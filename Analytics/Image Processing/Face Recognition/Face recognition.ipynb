{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facial Recognition\n",
    "##  Applications:\n",
    "### --> Surveillance system: Recognizing person(criminal/fugitive etc.) accross a video stream or CCTV.\n",
    "### -->  Identification/ Login or attendence system.\n",
    "<img src=\"image_1.png\" alt=\"model in action\">\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Theory\n",
    "### 1. CNN based model is used to detect Face(Results in very less number of false negatives\n",
    "### 2. Used Face-landmarks as feature to recognize faces(classification)\n",
    "<img src=\"image_2.png\" alt=\"Landmarks on Face\">\n",
    "### 3. Data preprocessing: \n",
    "#### Data images are filtered(containing multiple faces)\n",
    "#### --> Class imbalance is removed using resampling and SMOTE\n",
    "#### --> Partial Fit is used to incorporate incremental learning, so that data can repeatedly trained on old model without retraining as a whole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### libraries required:\n",
    "* Sklearn\n",
    "* Pandas,numpy\n",
    "* Pandas_ml\n",
    "* OpenCV,face_recognition(prebuild functions for dlib),dlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-12T08:50:25.698387Z",
     "start_time": "2018-01-12T08:50:10.630205Z"
    }
   },
   "outputs": [],
   "source": [
    "from facial_recognition import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='data_folder/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collecting Data\n",
    "* Data is collected via google images utility is developed which can download directly from google images\n",
    "*  Assumption(n=100) images from google are from same character(query) search for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing\n",
    "* For testing purpose we use cast list of different TV series and build model on top of that\n",
    "* For testing purpose TVDB or TMDB are used for getting cast list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TVDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([u'Lisa Kudrow', u'Matt LeBlanc', u'Matthew Perry', u'Courteney Cox', u'David Schwimmer', u'Jennifer Aniston'], 6)\n"
     ]
    }
   ],
   "source": [
    "series_name='friends'\n",
    "cast_list=get_cast_name_tvdb(series_name)\n",
    "print(cast_list,len(cast_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([u'Courteney Cox', u'Matt LeBlanc', u'Jennifer Aniston', u'David Schwimmer', u'Lisa Kudrow', u'Matthew Perry'], 6)\n"
     ]
    }
   ],
   "source": [
    "series_name='friends'\n",
    "cast_list=get_cast_name_tmdb(series_name)\n",
    "print(cast_list,len(cast_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading Data\n",
    "* once cast list is generated same can be used for downloading image, using <i> downloaded_images</i>\n",
    "* keywords : Extra text which is appended to each character in cast_list to filter down search more, ex Matt LeBlanc friends where friends is keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloaded_images(data_path=data_path+series_name+'/',cast_list=cast_list,keywords=[series_name]*len(cast_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Data\n",
    "-returns [X,y] write label file in models folder under data_path  \n",
    "\n",
    "* prepare data by passing reading path of images, minimum number of images(optional), maximum number of images(optional) and dump path\n",
    "* only those folder will be read which have minimum number of images(l_threshold), only those folder will be read which have minimum number of images(l_threshold default 20), \n",
    "* if number of images is greater than r_threshold that folder is ignored(default is None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dumping output\n",
      "returning prepare data\n"
     ]
    }
   ],
   "source": [
    "[X,y]=prepare_data(data_path=data_path+series_name+'/',l_threshold=10,dump_file_path=data_path+series_name+'/')\n",
    "#[X,y]=pickle.load(open(data_path+series_name+'/'+'_encoded_file.pickle','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training model\n",
    "* Incremental training is done using partial fit utility of sk-learn, thus trained model can be pass again as bas_more for new data \n",
    "* Wrote a custom function to train model, which take care of unbalanced classes using SMOTE and resampling\n",
    "* internally it will train multi based model until threshold_accuracy is reached, in each iteration training data is reshuffled. \n",
    "* number of retraining can be control by param n_retrain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entering training module\n",
      "StratifiedShuffleSplit(n_splits=10, random_state=0, test_size=0.2,\n",
      "            train_size=None)\n",
      "inside preprocessing function\n",
      "returning from preprocess data\n",
      "classes must be passed on the first call to partial_fit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/usr/local/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('accuracy in iteration ', 1, ' is =', 0.94936708860759489)\n",
      "returning from train module\n"
     ]
    }
   ],
   "source": [
    "clf_sgd=SGDClassifier(loss='log',n_jobs=7,\\\n",
    "                      shuffle=True,class_weight=None,warm_start=False\\\n",
    "                      ,n_iter = np.ceil(10**6 / 600),average=True)\n",
    "clf_sgd=train_model(clf_sgd,X,y,minm_image_process=100,threshold_accuracy=0.82,classes=list(range(1,10)),n_retrain=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(clf_sgd,open(data_path+series_name+'/'+'models/sgd_classifier.pickle','wb'),protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_sgd=pickle.load(open(data_path+series_name+'/'+'models/sgd_classifier.pickle','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing model\n",
    "* Testing can be done on any video(frames),\n",
    "* for downloading video we can use youtube-dl\n",
    "\n",
    "*We can use -F flag to check the format code and then -f flag to download that video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] 7qdwFQgMyVs: Downloading webpage\n",
      "[youtube] 7qdwFQgMyVs: Downloading video info webpage\n",
      "[youtube] 7qdwFQgMyVs: Extracting video information\n",
      "[info] Available formats for 7qdwFQgMyVs:\n",
      "format code  extension  resolution note\n",
      "249          webm       audio only DASH audio   52k , opus @ 50k, 1.62MiB\n",
      "250          webm       audio only DASH audio   69k , opus @ 70k, 2.05MiB\n",
      "171          webm       audio only DASH audio  121k , vorbis@128k, 3.54MiB\n",
      "140          m4a        audio only DASH audio  127k , m4a_dash container, mp4a.40.2@128k, 4.36MiB\n",
      "251          webm       audio only DASH audio  134k , opus @160k, 3.86MiB\n",
      "278          webm       256x144    144p  110k , webm container, vp9, 30fps, video only, 3.38MiB\n",
      "160          mp4        256x144    144p  111k , avc1.4d400c, 30fps, video only, 1.93MiB\n",
      "133          mp4        426x240    240p  201k , avc1.4d4015, 30fps, video only, 3.40MiB\n",
      "242          webm       426x240    240p  242k , vp9, 30fps, video only, 6.58MiB\n",
      "243          webm       640x360    360p  452k , vp9, 30fps, video only, 12.15MiB\n",
      "134          mp4        640x360    360p  476k , avc1.4d401e, 30fps, video only, 8.33MiB\n",
      "244          webm       854x480    480p  820k , vp9, 30fps, video only, 20.53MiB\n",
      "135          mp4        854x480    480p  947k , avc1.4d401f, 30fps, video only, 16.93MiB\n",
      "247          webm       1280x720   720p 1644k , vp9, 30fps, video only, 42.84MiB\n",
      "136          mp4        1280x720   720p 1785k , avc1.4d401f, 30fps, video only, 34.22MiB\n",
      "248          webm       1920x1080  1080p 2935k , vp9, 30fps, video only, 85.13MiB\n",
      "137          mp4        1920x1080  1080p 3420k , avc1.640028, 30fps, video only, 72.08MiB\n",
      "17           3gp        176x144    small , mp4v.20.3, mp4a.40.2@ 24k\n",
      "36           3gp        320x180    small , mp4v.20.3, mp4a.40.2\n",
      "43           webm       640x360    medium , vp8.0, vorbis@128k\n",
      "18           mp4        640x360    medium , avc1.42001E, mp4a.40.2@ 96k\n",
      "22           mp4        1280x720   hd720 , avc1.64001F, mp4a.40.2@192k (best)\n"
     ]
    }
   ],
   "source": [
    "!youtube-dl -F https://www.youtube.com/watch?v=7qdwFQgMyVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] 7qdwFQgMyVs: Downloading webpage\n",
      "[youtube] 7qdwFQgMyVs: Downloading video info webpage\n",
      "[youtube] 7qdwFQgMyVs: Extracting video information\n",
      "[download] Destination: Friends - HD - The Videotape-7qdwFQgMyVs.mp4\n",
      "\u001b[K[download] 100% of 72.08MiB in 01:18.75KiB/s ETA 00:0091\n"
     ]
    }
   ],
   "source": [
    "!youtube-dl -f 137 https://www.youtube.com/watch?v=7qdwFQgMyVs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### testing on a video \n",
    "*get_pred_on_frame returns prediction on frame*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_video_processed('Friends - HD - The Videotape-7qdwFQgMyVs.mp4',data_path=data_path+series_name+'/'\\\n",
    "                    ,model=clf_sgd,skip_frames=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### processed output\n",
    "<img src=\"image_3.png\" alt=\"Output of Model\">\n",
    "- Note: any output with less than .8 probablilty is not correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
